---
title: "`gspcr` walkthrough: main features"
output: 
  bookdown::html_document2:
    css: "style.css"
    number_sections: yes
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
vignette: >
  %\VignetteIndexEntry{main-features}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r klippy, echo = FALSE}
# Create a button for copy pasting code chunk to clipboard
klippy::klippy(position = c("top", "right"))

```

```{r global_options, include = FALSE}
# Load knitr package to change options
library(knitr)

# Set default options for the chunks
opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    comment = ""
)

# Set the width of the console output to a large number (for sidewise scroll)
options(width = 1e3)

```

SPCR regresses a dependent variable onto a few supervised principal components computed from a large set of predictors.
The **steps** followed by SPCR are the following:

1. Regress the dependent variable onto each column of a data set of *p* possible predictors via *p* simple linear regressions. This results in *p* bivariate association measures.
2. Define a subset of the original *p* variables by discarding all variables whose bivariate association measures less than a chosen threshold.
3. Use the subset of original data to estimate *q* PCs.
4. Regress the dependent variable onto the *q* PCs.

A key aspect of the method is that both the number of PCs and the threshold value used in step 2 can be determined by cross-validation.
GSPCR **extends** SPCR by allowing the dependent variable to be of any measurement level (i.e., ratio, interval, ordinal, nominal) by introducing likelihood-based association measures (or threshold types) in step 1.
Furthermore, GSPCR allows the predictors to be of any type by combining the PCAmix framework (Kiers, 1991; Chavent Et. Al., 2017) with SPCR in step 3.

# Features

This R package allows to:

- **Parameter tuning** of the threshold values and number of PCs;
- **Plot** the cross-validation trends used to tune the threshold value and the number of PCs to compute;
- **Estimate** the GSPCR model data set;
- **Predict** observations on both the training data and new, previously unseen, data

## Parameter tuning

Before we do anything else, let us **load the packages** we will need for this vignette.
If you don't have these packages, please install them using `install.packages()`.

```{r setup}
# Load R packages
library(gspcr)      # this package!
library(superpc)    # alternative comparison package
library(patchwork)  # combining ggplots

```

We start this vignette by estimating `gspcr` in a very simple scenario with a continuous dependent variable and a set of continuous predictors.
First, we store the **example dataset** `GSPCRexdata` (see the helpfile for details `?GSPCRexdata`) in two objects by preparing the data, prepare the data data

```{r}
# Comment goal of code
X <- GSPCRexdata$X$cont
y <- GSPCRexdata$y$cont

```

Then, we randomly select a **subset of the data** to use as a training set.
We use 90\% of the data as training data.

```{R}
# Set a seed
set.seed(20230415)

# Sample a subset of the data
train <- sample(x = 1:nrow(X), size = nrow(X) * .9)

```

Now we are ready to **use the** `cv_gscpr()` **function** to cross-validate the threshold value and the number of pcs to be used.

```{r }
# Train the GSPCR model
out <- cv_gspcr(
  dv = y[train],
  ivs = X[train, ]
)

```

We can then **extract** the cross-validated **solutions** from the resulting object.

```{R}
# Extract solutions
out$sol_table

```

## Graphical output

We can visually **examine the solution paths** produced by the cross-validation procedure by using the `plot()` functions.

```{R}
# Plot the solution paths
plot(out)

```

In this figure, the out-of-sample fit measure obtained with a given threshold value (X-axis) and a given number of principal components is reported on the Y-axis.
The values of the threshold considered are reported on the X-axis, and the X-axis title reports the type of threshold used, in this case, the simple regression model likelihoods.
For a different number of components considered, a different line is reported. The number of PCs is reported on the line.

Because the fit measure used by default for a continuous dependent variable is the F-statistic, we should look for the highest point on the Y-axis of this plot.
This point represents the best K-fold cross-validation fit.
As you see, the standard solution reported above matches the one presented in this plot.

## Estimation

Once the cross-validation procedure has identified the values of the threshold and the number of PCs that should be used, we can **estimate the GASPCR model** on the whole training data with the function `est_gspcr()`.

```{R}
# Estimate GSPCR on the whole training data
gspcr_est <- est_gspcr(
    dv = y[train],
    ivs = X[train, ],
    fam = "gaussian",
    ndim = out$sol_table[1, "Q"],
    active_set = out$pred_map[, out$sol_table[1, "thr_number"]]
)

```

## Prediction

We can now **obtain predictions** for new unseen data using the `predict()` function

```{R}
# Predict new data with constants
y_hat <- predict(
    object = gspcr_est,
    newdata = X[-train, ]
)

# Look at the first six predictions
head(y_hat)

```

# Details

We can now focus on three important details and decisions that should be considered when using the `gspcrs` approach.

## Association measures

As described in the introduction, `gspcr` allows for the specification of **different bivariate association measures**.
We can run `gspcr` using as a threshold type:

- the log-likelihoods of simple GLMs;
- the generalized $R^2$;
- the normalized association measure used in the `superpc` R package.

Another important aspect to consider is the **number of threshold values** that should be considered.
This can be specified with the `nthrs` argument.
Using the following code we can compare the solution paths obtained by the different association measures and values for a given number of PCs.

```{r}
#| label: fig-association-measures
#| fig-cap: "Solution paths for different association measures."
#| fig-width: 9
#| fig-height: 3

# Define a vector of threshold types
threshold_types <- c("LLS", "normalized", "PR2")

# Train the GSPCR model with the different values
out_trhs <- lapply(
    X = threshold_types,
    FUN = function(i) {
        cv_gspcr(
            dv = y,
            ivs = X,
            thrs = i,       # threshold type
            nthrs = 20,     # number of threshold values
            npcs_range = 1, 
            K = 10
        )
    }
)

# Plot them
plots <- lapply(out_trhs, function(i) {
    plot(
        x = i,
        y = "F",
        labels = FALSE,     # We are using a single nPC, do not need the label
        discretize = FALSE, # Makes X-axis more readable
        print = FALSE
    )
})

# Patchwork ggplots
plots[[1]] + plots[[2]] + plots[[3]]

```

As you can see, the solution paths are similar, although LLS tended to favor lower threshold values.

## Fit measures

We can use **different cross-validation fit measures**.
See the help file for the list options (`?cv_gspcr`).

```{r }
#| label: fig-fit-measures
#| fig-cap: "Solution paths for different fit measures."
#| fig-width: 9
#| fig-height: 6

# Measures
fit_measure_vec <- c("LRT", "PR2", "MSE", "F", "AIC", "BIC")

# Train the GSPCR model with the different values
out_fit_meas <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        fit_measure = i,
        thrs = "normalized",
        nthrs = 20,
        npcs_range = 1,
        K = 10
    )
})

# Plot them
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas[[i]],
        y = fit_measure_vec[[i]],
        labels = FALSE,
        y_reverse = rev,
        errorBars = FALSE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
(plots[[1]] + plots[[2]] + plots[[3]]) / (plots[[4]] + plots[[5]] + plots[[6]])

```

As you can see, the different fit measures return equivalent solution paths.
This is true for **any number of PCs**:

```{r }
#| label: fig-fit-measures-npc-5
#| fig-cap: "Solution paths for different fit measures when using 5 PCs."
#| fig-width: 9
#| fig-height: 6

# Train the GSPCR model with the different values
out_fit_meas <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        fit_measure = i,
        thrs = "normalized",
        nthrs = 20,
        npcs_range = 5,
        K = 10
    )
})

# Plot them
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas[[i]],
        y = fit_measure_vec[[i]],
        labels = FALSE,
        y_reverse = rev,
        errorBars = FALSE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
(plots[[1]] + plots[[2]] + plots[[3]]) / (plots[[4]] + plots[[5]] + plots[[6]])

```

## Number of components

We can use cross-validation to **select the number of PCs** as well.
We can use the `npcs_range` argument to specify the range of the number of PCs to consider.

```{r }
#| label: fig-cv-npcs
#| fig-cap: "Solution paths for different fit measures when cross-validating the number of PCs."
#| fig-width: 9
#| fig-height: 6

# Train the model
out_npcs <- cv_gspcr(
    dv = y[train],
    ivs = X[train, ],
    npcs_range = c(2, 5, 10)
)

# Plot solution paths
plot(out_npcs)

```

Given the choice of 2, 5, or 10 PCs, we would use 2 PCs with the second threshold value.

# Alternatives and comparisons

## Compare results with `superpc`

This package extends the `superpc` R package by introducing more fit measures and threshold types, which allows for the consideration of a wider range of variable types. 
Here we want to show that the **results** obtained by `superpc` can be **replicated** by `gspcr` when using the same fit measure and threshold type.

To use `superpc` we need to prepare the data in a different format.

```{R}
# Prepare data for superpc
data.train <- list(
    x = t(as.matrix(scale(X))),
    y = y,
    featurenames = colnames(X)
)

```

We can then train the model with the `superpc::superpc.train()` function and observe the solution paths.

```{R}
# Train the model (computes the scores for each feature)
train.obj <- superpc.train(
    data = data.train,
    type = "regression"
)

# Cross-validate the model
cv.obj <- superpc.cv(
    fit = train.obj,
    data = data.train,
    min.features = 1,
    max.features = nrow(data.train$x),
    n.fold = 10,
    n.threshold = 20,
    n.components = 5
)

# Cross-validation solution paths
cv.obj_plot <- superpc.plotcv(cv.obj)

```

Finally, we can specify and train `gspcr` in the same way and compare the cross-validation solution paths.

```{r }
# Train gspcr with the same specification as superpc
gspcr_superpc <- cv_gspcr(
    dv = y,
    ivs = X,
    fit_measure = "F",
    thrs = "normalized",
    nthrs = 20,
    npcs_range = 1:5,
    K = 10,
    min_features = 1,
    max_features = ncol(X)
)

# Create plot the cross-validation curves
plot(
    gspcr_superpc,
    errorBars = TRUE,
    discretize = FALSE,
)

```

We can also see that the thresholds values computed are exactly the same:

```{r}
# Report the threshold values
data.frame(
    superpc = round(cv.obj$thresholds, 3),
    gpscr = round(gspcr_superpc$thr, 3),
    diff = round(cv.obj$thresholds - gspcr_superpc$thr, 3)
)

```

## Is K-fold cross-validation working?

In this section, I want to showcase the effectiveness of using cross-validation to **select the number of PCs** for GSPCR.
We can estimate the same solution paths for GSPCR with and without using K-fold cross-validation by changing the number of folds used.
If we set `K = 1` in the `cv_gspcr()` call, the data is assigned a single fold, and the fit measures are evaluated on the same data the model is trained on.

First, let's estimate the solution paths with K-fold cross-validation.
To keep the comparison simple, we specify two options for the number of PCs (5 and 20), but any other set of values could be used.
We train the model with the six available fit measures stored in the object `fit_measure_vec`.

```{r }
#| label: fig-cv-check
#| fig-cap: "Solution paths for different fit measures using K-fold CV."
#| fig-width: 9
#| fig-height: 6
# Train the GSPCR model with two number of PCs options
out_fit_meas_cv <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        K = 10,
        npcs_range = c(5, 20),
        fit_measure = i,
        thrs = "normalized"
    )
})

# Plot solution paths
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas_cv[[i]],
        y = fit_measure_vec[[i]],
        labels = TRUE,
        y_reverse = rev,
        errorBars = FALSE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
(plots[[1]] + plots[[2]] + plots[[3]]) / (plots[[4]] + plots[[5]] + plots[[6]])

```

Then, we repeat the same procedure but we set `K = 1`, to avoid K-fold cross-validation.

```{r }
#| label: fig-cv-check-no-cv
#| fig-cap: "Solution paths for different fit measures without using K-fold CV."
#| fig-width: 9
#| fig-height: 6
# Train the GSPCR model with many number of components
out_fit_meas_no_CV <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        K = 1,
        npcs_range = c(5, 20),
        fit_measure = i,
        thrs = "normalized"
    )
})

# Plot them
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas_no_CV[[i]],
        y = fit_measure_vec[[i]],
        labels = TRUE,
        y_reverse = rev,
        errorBars = TRUE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
(plots[[1]] + plots[[2]] + plots[[3]]) / (plots[[4]] + plots[[5]] + plots[[6]])

```

You can already see from the plots that when using LRT, MSE, and PR2 as fit measures, without cross-validation we would end up selecting the highest number of PCs provided (20 in this case).
However, when using K-fold cross-validation, the solution paths would lead us to choose 5 PCs instead.

We can also look at the solutions tables to confirm our read of the plots. 
The solution we would have found using K-fold CV is:

```{r }
# Standard solutions
res_CV <- sapply(
    1:length(out_fit_meas_cv),
    function(meth) {
        as.numeric(out_fit_meas_cv[[meth]]$sol_table["standard", ])
    }
)

# Give meaningful names
dimnames(res_CV) <- list(c("thr_value", "thr_number", "Q"), fit_measure_vec)

# Print rounded results
round(t(res_CV), 3)

```

The solutions we would have obtained without using K-fold CV are:

```{r }
# Standard solutions
res_no_CV <- sapply(
    1:length(out_fit_meas_no_CV),
    function(meth) {
        as.numeric(out_fit_meas_no_CV[[meth]]$sol_table["standard", ])
    }
)

# Give meaningful names
dimnames(res_no_CV) <- list(c("thr_value", "thr_number", "Q"), fit_measure_vec)

# Print rounded results
round(t(res_no_CV), 3)

```

As you can see, using CV we find the same solution no matter what the outcome measure, while without using CV, only the AIC, BIC, and F are able to select a low number of PCs.

## 1SE solutions

The results for all fit measures except `F` struggle with accounting for measure complexity. The use of a simple 1-standard-error rule helps obviate this problem.
First, fit the models with many possible number of components:

```{r }
#| label: fig-1se-rule
#| fig-cap: "Solution paths for different fit measures when using the 1-standard-error rule."
#| fig-width: 9
#| fig-height: 6

# Train the GSPCR model with many number of components
out_fit_meas <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        fam = "gaussian",
        nthrs = 10,
        npcs_range = 1:10,
        K = 10,
        fit_measure = i,
        thrs = "normalized",
        min_features = 1,
        max_features = ncol(X),
        oneSE = TRUE
    )
})

# Plot them
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas[[i]],
        y = fit_measure_vec[[i]],
        labels = TRUE,
        y_reverse = rev,
        errorBars = TRUE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
(plots[[1]] + plots[[2]] + plots[[3]]) / (plots[[4]] + plots[[5]] + plots[[6]])

```

Then, extract the solutions obtained by each:

```{r }
# Standard solutions
res <- sapply(
    1:length(out_fit_meas),
    function(meth) {
        as.numeric(out_fit_meas[[meth]]$sol_table["standard", ])
    }
)

# Give meaningful names
dimnames(res) <- list(c("thr_value", "thr_number", "Q"), fit_measure_vec)

# Print rounded results
round(t(res), 3)

```

Finally, you can check which solutions would be chosen by using the 1-standard-error rule:

```{r }
# 1se solutions
res_1se <- sapply(
    1:length(out_fit_meas),
    function(meth) {
        as.numeric(out_fit_meas[[meth]]$sol_table["oneSE", ])
    }
)

# Give meaningful names
dimnames(res_1se) <- list(c("thr_value", "thr_number", "Q"), fit_measure_vec)

# Print rounded results
round(t(res_1se), 3)

```

## Alternatives to CV

To speed up the model-fitting process, it can be a good idea to find model-building strategies that are less time-consuming than CV.
You can use the BIC fit measure without CV to select the appropriate threshold value and the number of components.
To do so, you can specify the number of folds to 1 and the fit measure to BIC or AIC.

```{r }
#| label: fig-no-cv
#| fig-cap: "Solution paths obtained using fit measures that do not need K-fold CV."
#| fig-width: 9
#| fig-height: 3

# Define vector of measures to be used
fit_measure_vec <- c("LRT", "AIC", "BIC")

# Train the GSPCR model with the different values
out_fit_meas <- lapply(fit_measure_vec, function(i) {
    cv_gspcr(
        dv = y,
        ivs = X,
        fam = "gaussian",
        nthrs = 10,
        npcs_range = c(1, 2, 5, 20),
        K = 1,
        fit_measure = i,
        thrs = "normalized",
        min_features = 1,
        max_features = ncol(X),
        oneSE = TRUE
    )
})

# Plot them
plots <- lapply(seq_along(fit_measure_vec), function(i) {
    # Reverse y?
    rev <- grepl("MSE|AIC|BIC", fit_measure_vec[i])

    # Make plots
    plot(
        x = out_fit_meas[[i]],
        y = fit_measure_vec[[i]],
        labels = TRUE,
        y_reverse = rev,
        errorBars = FALSE,
        discretize = FALSE,
        print = FALSE
    )
})

# Patchwork ggplots
plots[[1]] + plots[[2]] + plots[[3]]

```

You can also look at the solutions:

```{r }
# Put solutions together
rbind(
    LRT = out_fit_meas[[1]]$sol_table["standard", ],
    AIC = out_fit_meas[[2]]$sol_table["standard", ],
    BIC = out_fit_meas[[3]]$sol_table["standard", ]
)

```

# TL;DR, just give me the code!

```{r TLDR, ref.label = knitr::all_labels()[!knitr::all_labels() %in% c("global_options", "klippy")], echo = TRUE, eval = FALSE}
```

<!-- Remove white space generated by toc_float -->
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

# References

Bair E, Hastie T, Paul D, Tibshirani R (2006). “Prediction by supervised principal components.” J. Am. Stat. Assoc., 101(473), 119-137.

Chavent, M., Kuentz-Simonet, V., Labenne, A., & Saracco, J. (2014). Multivariate analysis of mixed data: The R package PCAmixdata. arXiv preprint arXiv:1411.4911.

Kiers, H. A. (1991). Simple structure in component analysis techniques for mixtures of qualitative and quantitative variables. Psychometrika, 56(2), 197-212.